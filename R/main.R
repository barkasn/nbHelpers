#' @author Nikolas Barkas
#' @importFrom utils read.table
#' @importFrom Matrix readMM
NULL

#' @title Find minimum string distance strings in a vector
#' @description Find the minimum string distance between strings in a vector,
#' this is useful for things like finding the number of allowable barcode
#' mismatches
#' @importFrom stringdist stringdistmatrix
#' @export minStringDistance
minStringDistance <- function(strings) {
  ds <- stringdist::stringdistmatrix(strings,strings);
  min(ds[upper.tri(ds)])
}

#' @title  Read 10x matrix
#' @description This function reads a matrix generated by the 10x processing pipeline
#' from the specified directory and returns it. It aborts if one of the required
#' files in the specified directory do not exist.
#' @param path location of 10x output
#' @return read matrix
#' @import Matrix
#' @import methods
#' @export read10xMatrix
read10xMatrix <- function(path) {
  matrixFile <- paste(path, 'matrix.mtx', sep='/');
  genesFile <- paste(path, 'genes.tsv', sep='/');
  barcodesFile <- paste(path, 'barcodes.tsv', sep='/');

  if (!file.exists(matrixFile)) { stop('Matrix file does not exist');  }
  if (!file.exists(genesFile)) { stop('Genes file does not exist'); }
  if (!file.exists(barcodesFile)) { stop('Barcodes file does not exist'); }

  x <- as(Matrix::readMM(matrixFile), 'dgCMatrix')

  genes <- read.table(genesFile)
  rownames(x) <- genes[,2];

  barcodes <- read.table(barcodesFile);
  colnames(x) <- barcodes[,1]
  invisible(x);
}

#' @title wrapper with old name for read10xmatrices
#' @export readMultiple10Xmatrices
readMultiple10Xmatrices <- function(...) {
    readmultiple10xmatrices(...);
}

#' @title read multiple 10x matrices into a single sparse array
#' @description given a named list of paths of 10X matrices return a single large matrix
#' with all the data and cell prefixed with the corresponding sample name
#' @param paths named vector of location of the data (readable by read10Xmatrix())
#' @param min.common.genes minimum number of common genes to allow
#' @param common.genes logical, subset all matrices to common genes, required for merge
#' @param merge logical, merge all the matrices to one, requires common.genes and prefix.cells
#' @param prefix.cells prefix all cells with the name of the respective path in paths
#' @param prefix.sep separator for prefix of cells
#' @return a sparce matrix of the Matrix package that contains all the data prefixes by the corresponding sample name
#' @export read10xmatrices
read10xmatrices <- function(paths, min.common.genes = 1000, common.genes = T, merge =T, prefix.cells=T,
                            prefix.sep = '_') {
  if (merge && !common.genes) stop("Can't merge matrices if common.genes is not set. Aborting.");
  if (merge && !prefix.cells) stop("Can't merge matrices if prefix.cells is not set. Aborting.");

  # Read the matrices one by one
  matrices <- sapply(paths, read10xMatrix)

  ## Prefix the arrays
  if (prefix.cells) {
      matrices <- mapply(
          function(m, name) {
              colnames(m) <- paste(name, colnames(m), sep=prefix.sep);
              m
          },
          matrices,
          names(matrices)
      )
  }

  ## Merge the arrays
  if (merge) {
      ## Get the genes in each array
      genelists <- lapply(matrices, function(x) rownames(x))
      ## Find the common genes
      commongenes <- Reduce(intersect,genelists)
      ## Stop if common genes too low
      if (length(commongenes) < min.common.genes) stop('The number of common genes is too low!');
      # Subset to common genes
      matrices <- mapply(
          function(m, name) {
              m[commongenes,]
          },
          matrices,
          names(matrices)
      )

      if (merge) {
          matrices <- Reduce(cbind, matrices)
      }
  }


  ## Return
  matrices
}


#' @title get NW, NE, SW and SE corners of a dataframe or matrix
#' @description return a new dataframe or matrix with the elements at the
#' four corners of the one provided
#'
#' @param vals the dataframe or matrix of interest
#' @param n how many rows/cols to return from each end
#'
#' @return the new matrix
#'
#' @export tableCorners
tableCorners <- function(vals, n = 4) {
  if (is.null(vals)) error("vals is NULL");
  if (n < 1) error("Invalid value for n");

  d <- dim(vals)
  rows <- c(1:n,(d[1]-n):(d[1]))
  cols <- c(1:n,(d[2]-n):(d[2]))
  vals[rows, cols]
}


#' @title save a R session image fast
#' @description saves an R image of the current session much faster and with
#' better compression that the built-in save.image function. Requires system lbzip2
#' utility
#' @param filename the file to save the image to
#' @param tmpfile optional temporary file name, using a ramdisk location will further accelerate saving
#' @param verbose logical verbosity level
#' @export save.image.fast
save.image.fast <- function(filename,tmpfile = NULL, verbose = FALSE) {
  if (is.null(filename)) {
    stop("filename argument is required");
  }
  if (is.null(tmpfile)) {
    tmpfile <- tempfile();
  }

  if (verbose) { cat('Saving to temp file ', tmpfile,'\n') }
  save.image(tmpfile, compress = FALSE);

  cmd <- paste0('lbzip2 -c ', tmpfile, ' > ', filename)

  if (verbose) { cat('Compressing...\n') };
  system(cmd);

  if (verbose) { cat('Deleting temporary file...') }
  unlink(tmpfile)
}

#' Loads an image generated with save.image.fast()
#' @description loads an image generated with the save.image.fast function. This function
#' requires that the system has the lbunzip2 command installed
#' @param filename filename to load
#' @param tmpfile temporary file to use, use of ramdisk file will accelerate loading
#' @param verbose logical verbosity level
#' @param envir enviroment in which to load the data, by default the calling environment
#' @export load.image.fast
load.image.fast <- function(filename, tmpfile = NULL, verbose=F, envir = parent.frame()) {
  if (is.null(filename)) {
    stop('filename argument is required');
  }
  if (is.null(tmpfile)) {
    tmpfile <- tempfile();
  }

  if (verbose) { cat('Decompressing into temporary file ', tmpfile, '...\n') }
  cmd <- paste0('lbunzip2 -c ', filename, ' > ', tmpfile);
  system(cmd);

  if  (verbose) { cat('Loading...\n') }
  load(tmpfile, envir = envir);

  if (verbose) { cat('Deleting temporary file...\n') }
  unlink(tmpfile);
}

#' Generates a new vector from two vectors by combining them according to a third
#' @description generates a vector from two vectors depending of the logical value of
#' a third vector
#' @param logical vector to use to combine the vTrue and vFalse vectors
#' @param vTrue values to return if the logical is true
#' @param vFalse values to return if the logical is false
#' @return a new vector with some values from vTrue and some for vFalse
#' @export mixVectorsOnLogical
mixVectorsOnLogical <- function(logical,vTrue,vFalse) {
  mapply(function(v, vt, vf) {ifelse(v, vt, vf)}, logical, vTrue, vFalse);
}

#' Generates a random positive definite matrix
#' @description generates a random positive definite matrix with the specified
#' eigenvalues. Code from: https://stat.ethz.ch/pipermail/r-help/2008-February/153708.html
#' @param n dimensions
#' @param ev optional eigenvalues
#' @return a random positive definite matrix with requested eigenvalues
#' @export randomPositiveDefiniteMatrix
randomPositiveDefiniteMatrix <- function(n, ev = runif(n, 0, 10)) {
  Z <- matrix(ncol=n, rnorm(n^2))
  decomp <- qr(Z)
  Q <- qr.Q(decomp)
  R <- qr.R(decomp)
  d <- diag(R)
  ph <- d / abs(d)
  O <- Q %*% diag(ph)
  Z <- t(O) %*% diag(ev) %*% O
  return(Z)
}



#' Generates data with covariance structure specified by the given covariance matrix
#' @description Generates the requested number of observations that follow the given
#' covariance structure specified by the given matrix
#' @param covM a posititive definite covariance matrix
#' @param nobs the number of observations requestest
#' @return data.frame object with the observations as rows and the variables as columns
#' @import matrixcalc
#' @export getDataWithCovarianceMatrix
getDataWithCovarianceMatrix <- function(covM, nobs) {
  # https://www.r-bloggers.com/simulating-data-following-a-given-covariance-structure/

  covDim <- dim(covM)
  nvars <- covDim[2]

  if (nobs < 1)
    stop('No observations were requested')

  if (covDim[1] != covDim[2])
    stop('Covariance matrix is not square!')

  if (!matrixcalc::is.positive.definite(covM)) {
    stop('Covariance matrix is not positive definite!')
  }

  as.data.frame(t(t(chol(covM)) %*% matrix(rnorm(nvars*nobs), nrow=nvars, ncol=nobs)))
}



#' Makes an array with artificial doublets by adding cells together
#' @description makes an array with artificial doublets  by adding cells together
#' @param cm count matrix, rows are genes, cols are cells
#' @param group1 group1 to sample from
#' @param group2 group2 to sample from
#' @param mix.ratio.min minimum mixing ratio
#' @param mix.ratio.max maximum mixing ratio
#' @param n number of cells to generate
#' @return a new array with artificial doublets
#' @importFrom parallel mclapply
#' @export make.doublets.two.groups.add
#' @examples
#'
#' group1 <- colnames(cm)[sample(1:length(colnames(cm)),1000)]
#' group2 <- colnames(cm)[sample(1:length(colnames(cm)),1000)]
#' int <- intersect(group1,group2)
#' length(int)
#' group1 <- setdiff(group1, int)
#' group2 <- setdiff(group2, int)
#' doublets <- make.doublets(cm=cm, group1=group1, group2=group2, mix.ratio.min=0.4,mix.ratio.max=0.6, n=100, mc.cores=40)
make.doublets.two.groups.add <- function(cm, group1, group2, mix.ratio.min, mix.ratio.max, n, mc.cores=1) {

  gene.list <- rownames(cm)

  mx.rs <- runif(n,mix.ratio.min,mix.ratio.max)

  x <- parallel::mclapply(mx.rs,function(mx.r){
    # Pick two cells and a mixing ratio making sure cell 2 is not the same as cell 1
    c1.name <- group1[floor(runif(1,1,length(group1)))]

    c2.name <- c1.name
    while(c2.name == c1.name) {
      c2.name <- group2[floor(runif(1,1,length(group2)))]
    }

    r <- cm[,c1.name] + cm[,c2.name]

    r
  }, mc.cores=mc.cores)

  x2 <- do.call(rbind,x)
  rownames(x2) <- paste0('doublet_',1:n)

  invisible(t(x2))
}


#' Makes an array with artificial doublets by subsampling of different mix ratios
#' @description makes an array with artificial doublets  by subsampling of different mix ratios
#' @param cm count matrix, rows are genes, cols are cells
#' @param group1 group1 to sample from
#' @param group2 group2 to sample from
#' @param mix.ratio.min minimum mixing ratio
#' @param mix.ratio.max maximum mixing ratio
#' @param n number of cells to generate
#' @param oversample oversample/undersampling oversampling of reads
#' @return a new array with artificial doublets
#' @importFrom parallel mclapply
#' @export make.doublets.two.groups.subsample
#' @examples
#'
#' group1 <- colnames(cm)[sample(1:length(colnames(cm)),1000)]
#' group2 <- colnames(cm)[sample(1:length(colnames(cm)),1000)]
#' int <- intersect(group1,group2)
#' length(int)
#' group1 <- setdiff(group1, int)
#' group2 <- setdiff(group2, int)
#' doublets <- make.doublets(cm=cm, group1=group1, group2=group2, mix.ratio.min=0.4,mix.ratio.max=0.6, n=100, mc.cores=40, oversample = 1.5)
make.doublets.two.groups.subsample <- function(cm, group1, group2, mix.ratio.min, mix.ratio.max, n, mc.cores=1, oversample = 1.5) {

  gene.list <- rownames(cm)

  mx.rs <- runif(n,mix.ratio.min,mix.ratio.max)

  x <- parallel::mclapply(mx.rs,function(mx.r){
    # Pick two cells and a mixing ratio making sure cell 2 is not the same as cell 1
    c1.name <- group1[floor(runif(1,1,length(group1)))]

    c2.name <- c1.name
    while(c2.name == c1.name) {
      c2.name <- group2[floor(runif(1,1,length(group2)))]
    }

    # Alternative ways of doing this by sampling reads

    c1.tmp <- rep(gene.list,cm[,c1.name])
    c2.tmp <- rep(gene.list,cm[,c2.name])
    c1.l <- length(c1.tmp)
    c2.l <- length(c2.tmp)

    c1.tmp <- c1.tmp[sample(1:c1.l,c1.l*mx.r*oversample)]
    c2.tmp <- c2.tmp[sample(1:c2.l,c2.l*(1-mx.r)*oversample)]
    all.tmp <- c(c1.tmp,c2.tmp)
    r <- table(all.tmp)[gene.list]
    r[is.na(r)] <- c(0)
    names(r) <- gene.list

    r
  }, mc.cores=mc.cores)

  x2 <- do.call(rbind,x)
  rownames(x2) <- paste0('doublet_',1:n)

  invisible(t(x2))
}

#' Convert list of lists of numbers to array
#' @description Converts lists of lists of numbers to a numeric array fast
#' this has been optimised against other possible implementations and
#' been found to the the fastest
#' @param inputList a list of lists of numbers
#' @return an array where the top-level lists are rows and low-level lists are columns
#' @examples
#' mylist <- list()
#' mylist_ <- list()
#' for(i in 1:10) {
#'   for(j in 1:100) {
#'     mylist[[j]] <- i*j
#'   }
#'   mylist_[[i]] <- mylist
#' }
#' str(mylist_)
#' r3 <- ll2a.3(mylist_)
#' @export ll2a
ll2a <- function(inputList){
  f <- as.matrix(as.data.frame(sapply(inputList, function(x) (unlist(x)),simplify = F),stringsAsFactors = F,as.is=T))
  rownames(f) <- NULL
  colnames(f) <- NULL

  t(f)
}

#' Reads in an expression matrix as formatted by the Klein lab
#' pipeline
#' @param path path of the file
#' @param prefix prefix to add to the cell names
#' @return a sparse matrix
#' @import Matrix
#' @export readKleinMatrix
readKleinMatrix <- function(path, prefix) {
  require(Matrix)

  matrix <- read.table(path, header=T, row.names=1, sep='\t', as.is=T, stringsAsFactors=F)
  matrix <- data.matrix(matrix)
  rownames(matrix) <- paste0(prefix, '_' ,rownames(matrix))
  matrix <- Matrix(t(matrix), sparse=T)

  matrix
}

#' Reads in multiple klein matrices and returns them in a list
#' @param file.names named list of the files to load, the names will become prefixes
#' @return a list of sparse matrices
#' @export readMultipleKleinMatrices
readMultipleKleinMatrices <- function(file.names) {
 mapply(readKleinMatrix, file.names, names(file.names))
}

#' Reads in a data matrix from the in house indrop pipeline
#' @param name prefix to give to cells
#' @param path the file path
#' @return a sparse expression matrix
#' @export readInDropMatrix
readInDropMatrix <- function(name, path) {
  m <- readRDS(path);
  m <- m$cm
  colnames(m) <- paste(name, colnames(m), sep='_')
  m
}

#' Reads in multiple indrop matrices
#' @param file.names named vector of filenames, names will become prefixes
#' @return list of matrices
#' @export readMultipleInDropMatrices
readMultipleInDropMatrices <- function(file.names) {
  mapply(readInDropMatrix, names(file.names),file.names)
}

#' Merge expression matrices in a list, keeping only common genes
#' @param data.all a list of sparse matrices
#' @param prefix.names logical, denoting whether to prefix the cell names with the table name
#' @param prefix.sep character, separator to use between sample and cell name, defaults to _
#' @return a single merged matrix
#' @export mergeMatrices
mergeMatrices <- function(data.all, prefix.names=T, prefix.sep = '_') {
  common.genes <- Reduce(intersect, lapply(data.all, function(x) {rownames(x)}))

  data.all.common <- mapply(function(x, name) {
    y <- x[common.genes,]
    if(prefix.names) {
      colnames(y) <- paste0(name, prefix.sep,  colnames(y))
    }
    y
  }, data.all, names(data.all))
  x <- do.call(cbind, data.all.common)

  x
}

#' Write a list of data.frames as individual csv files
#' @description Write a list of data.frames as individual csv files
#' @param x named list of data.frames
#' @param output.dir the directory to save the files in
#' @export writeListOfDFs
writeListOfDFs <- function(x, output.dir) {
  # TODO: Add checks: list is named; elements are data.frames; output.dir exists

  mapply(function(x,name) {
    write.table(x, paste0(output.dir,'/',name,'.csv'))
  }, deres, names(deres));

  invisible(NULL)
}

#' @title read multiple 10x matrices and return as a list
#' @description given a named list of paths of 10X matrices return a list of matrices
#' @param matrices a names list of paths to the matrices (that can be read by read10XMatrix)
#' @return a list
#' @export readMultiple10XmatricesAsList
readMultiple10XmatricesAsList <- function(pathList) {
  # Read the matrices one by one
  matrices <- sapply(pathList, read10xMatrix)

  invisible(matrices)
}

#' Get the colors of a pagoda1 serialised app object as a factor
#' @description get the colors of a pagoda1 serialised app object as a factor from the app$results$colcol list
#' @param filename the rds file to load
#' @param colcol.name the name of the colcol item to retrive
#' @return a named factor
getFactorFromP1rds <- function(filename, colcol.name) {
  app <- readRDS(filename)
  env <- app@.xData
  app2 <- as.list(env)
  colcol <- app2$results$colcol
  fac <- colcol[[colcol.name]]$data
  fac
}

#' Generate a ggplot2 plot comparing two factors for a common set of datapoints
#' @description Generates a ggplot barplot that compares two names two nameed factors
#' for the specified points. The x axis corresponds to factor B and the y axis
#' factor A.
#' @param factorA the factor the distibution of which with respect to factorB will be assessed (y axis)
#' @param factorB the factor to breakdown factorA by
#' @param points the names of the elemets of the factorsA and factorB to include for the
#' purposed of the plot
#' @examples
#' fA <- rep(c('A','B','C','D'), each = 4);
#' fB <- rep(c('W','Y'), each = 8)
#' n <- paste0('n',1:16)
#' names(fA) <- n
#' names(fB) <- n
#' plotFactorsPercent(fA, fB, points = names(fA)[1:9])
plotFactorsPercent <- function(factorA, factorB, points = NULL, factorA.name = 'factorA', factorB.name = 'factorB' ) {
  require(ggplot2)
  require(reshape2)

  if (is.null(points)) {
    if (!(all(names(factorA) %in% names(factorB)) & all(names(factorB) %in% names(factorA)))) {
      points <- intersect(names(factorA), names(factorB))
      warning("points is null and the two factors contain different elements: using only common elements")
    } else {
      points <- names(factorA)
    }
  }

  tmpdf <- data.frame(factorA=factorA[points], factorB = factorB[points]);
  tmpa <- acast(tmpdf, factorA ~ factorB, fun.aggregate=length, value.var='factorB')

  tmpa.norm <- sweep(tmpa, 2, colSums(tmpa), FUN='/')
  tmpa.norm.m <- melt(tmpa.norm)

  ggplot(tmpa.norm.m, aes(x=as.factor(Var2), y=value, fill=as.factor(Var1))) + geom_bar(stat='identity') +
    scale_x_discrete(name = factorB.name) + scale_fill_discrete(name = factorA.name) +
    scale_y_continuous(name=paste0('proportion of ',factorA.name))
}


#' Get all unique combinations of elements in a list
#' @param nms elements to get combinations
#' @return list of pairs of elements
#' @importFrom gtools combinations
#' @export uniqCombs
uniqCombs <- function(nms) {
    nms <- unique(nms)

    combs <- combinations(n = length(nms), r = 2, v = nms, repeats.allowed =F)
    ret <- split(t(combs), rep(1:nrow(combs), each=ncol(combs)))

    ret
}

#' Save the session in the current working directory with a file name that
#' includes the time stamp and process id
#' @param prefix the prefix to use,for the filename
#' @export preserve.state
preserve.state <- function(prefix='savepoint_') {
  file <- paste0(prefix,gsub(' ','_',Sys.time()),'_',Sys.getpid(),'.RDataF')
  save.image.fast(file)
}

